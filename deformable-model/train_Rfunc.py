"""Script to build R function

use randon forest regressor to fit the features generated by real-world CT data
R function is used to adjust the image gradient at face centers

用来检测到底是不是边缘
输入：带验证边缘的梯度和像素值
输出：【-1，1】，来表征是否为边缘

"""
import numpy as np
from file_importer import read_ply,read_mhd
from mesh_util import face_center, face_normal, elementwise_normalize
from interpolation.splines import LinearSpline
from sklearn.ensemble import RandomForestRegressor
from sklearn.externals import joblib


def safe_read_ply(fname):
    try:
        m = read_ply(fname, normal=False)
    except FileNotFoundError:
        m = None
    return m


def build_linear_interp_func(data):
    d0, d1, d2 = data.shape
    a = np.array([0, 0, 0])
    b = np.array([d0 - 1, d1 - 1, d2 - 1])
    orders = np.array([d0, d1, d2])
    # LinearSpline ？？
    lin = LinearSpline(a, b, orders, data)
    return lin


def get_feature_of_one_vertebra(data, grad, spacing, m):
    if m is None:
        return None
    else:
        return get_feature_of_one_vertebra_core(data, grad, spacing, m)


def get_feature_of_one_vertebra_core(data, grad, spacing, m, delta=1 / 3, k=2):
    feat = []
    sample_parcel = [i * delta for i in range(-k, k + 1)]
    verts, faces = m
    fcenters = face_center(verts, faces)
    fcenters /= spacing
    fnormals = elementwise_normalize(face_normal(verts, faces))
    fnormals /= spacing
    grad1_interp = grad[0]
    grad2_interp = grad[1]
    grad3_interp = grad[2]

    for d in sample_parcel:
        moved_fcenters = fcenters + (d * fnormals)
        intensity = data(moved_fcenters)
        grad1 = grad1_interp(moved_fcenters)
        grad2 = grad2_interp(moved_fcenters)
        grad3 = grad3_interp(moved_fcenters)
        direct_cosine = np.sum(np.c_[grad1, grad2, grad3] * fnormals, axis=1)
        feat.append(np.c_[intensity, direct_cosine])

    return np.hstack(feat)


def get_features_of_one_spine(data, spacing, vertebras):
    features = []
    grad = np.gradient(data)
    grad1_interp = build_linear_interp_func(grad[0])
    grad2_interp = build_linear_interp_func(grad[1])
    grad3_interp = build_linear_interp_func(grad[2])
    grad = (grad1_interp, grad2_interp, grad3_interp)
    data = build_linear_interp_func(data)

    for m in vertebras:
        feat = get_feature_of_one_vertebra(data, grad, spacing, m)
        features.append(feat)
    return features


def normalize(data):
    data = data.astype(dtype=np.float32)
    dmax, dmin = data.max(), data.min()
    data = (data - dmin) / (dmax - dmin)
    return data


def transpose(features):
    return [[features[j][i] for j in range(len(features))] for i in range(len(features[0]))]


def cut2align(array_list):
    nrows = np.array([a.shape[0] for a in array_list if a is not None])
    nrows = nrows.min()
    new_array_list = [a[:nrows, :] for a in array_list if a is not None]
    return new_array_list


def mean_array_list(array_list):
    sum = np.zeros_like(array_list[0])
    for array in array_list:
        sum += array
    return sum / len(array_list)


def extract_featrues():
    features = []
    for sidx in range(1, 11):
        print('extracting features of case {} ...'.format(sidx))
        data, spacing = read_mhd('../data0_raw/case{}.mhd'.format(sidx))
        data = normalize(data)
        vertebras = [safe_read_ply('../data2_simplify/s{}v{}.ply'.format(sidx, vidx)) for vidx in range(3, 20)]
        feat = get_features_of_one_spine(data, spacing, vertebras)
        features.append(feat)
    features = transpose(features)
    features = [cut2align(array_list) for array_list in features]
    features = [mean_array_list(array_list) for array_list in features]
    features = [np.hsplit(array_list, array_list.shape[1] // 2) for array_list in features]
    return features


def safe_row_concat(a, b):
    if a is None:
        return b
    else:
        return np.r_[a, b]


def build_train_datasets(vertebra_features):
    nfeature = len(vertebra_features)
    k = nfeature // 2
    nrow = vertebra_features[0].shape[0]
    halfe = np.linspace(-1, 1, k + 1)[:-1]
    e = np.r_[halfe, 1, halfe[::-1]]
    X = None
    y = None

    for i, feat in enumerate(vertebra_features):
        X = safe_row_concat(X, feat.astype(np.float32))
        y = safe_row_concat(y, np.full(nrow, e[i], dtype=np.float32))

    return X, y


def error(rfr, X, y):
    return np.sqrt(np.mean((y - rfr.predict(X)) ** 2))


features = extract_featrues()

for i, features_of_vertebra in enumerate(features, start=3):
    X, y = build_train_datasets(features_of_vertebra)
    np.save('../data_others/Rfunc/X_at_v{}.npy'.format(i), X)
    np.save('../data_others/Rfunc/y_at_v{}.npy'.format(i), y)

    rfr = RandomForestRegressor(n_estimators=10, n_jobs=-1)
    rfr = rfr.fit(X, y)
    joblib.dump(rfr, '../data_others/Rfunc/v{}.pkl'.format(i))
    print('err = {}'.format(error(rfr, X, y)))

# for i in range(2, 20):
#     X = np.load('../data_others/Rfunc/X_at_v{}.npy'.format(i))
#     y = np.load('../data_others/Rfunc/y_at_v{}.npy'.format(i))
#     rfr = joblib.load('../data_others/Rfunc/v{}.pkl'.format(i))
#     print('err = {}'.format(error(rfr, X, y)))
